# Лабораторная работа №5  
## Сбор и интеграция данных, инжиниринг признаков и отбор признаков

---

### Что делаем

- Объединяем данные из разных источников  
- Приводим к общей структуре  
- Удаляем дубликаты  
- Проверяем данные на корректность  

---

### Инжиниринг числовых признаков

- Заменили все значения `-1` на `NaN`  
- Построили графики распределения ключевых числовых признаков  
- Преобразовали логические признаки в бинарный вид (0,1)  
- Разбили признак CO на 3 группы  
- Ограничили значения давления  
- Удалили строки с более чем 2 пропущенными значениями  
- Заполнили пропуски (импутация)  
- Нормализовали числовые признаки с помощью `MinMaxScaler`  

---

### Инжиниринг категориальных признаков

- Загрузили данные, провели первичный анализ  
- Визуализировали распределение категориальных признаков и их связь с целевой переменной  
- Объединили редкие категории в группу `Other`  
- Применили бинаризацию некоторых признаков (one-hot encoding)  
- Добавили агрегированные признаки  

#### Основные методы преобразования категориальных признаков

1. **One-Hot Encoding**  
   Каждая категория представляется отдельным бинарным признаком (столбцом), где `1` — принадлежность категории, `0` — отсутствие.  
   Пример:  
   Цвет: красный → `[1,0,0]`, синий → `[0,1,0]`, зелёный → `[0,0,1]`.

2. **Label Encoding**  
   Каждой категории присваивается уникальное число, например, красный=0, синий=1, зелёный=2.  
   Внимание: этот метод вводит порядок между категориями, которого может не быть в данных.

3. **Target Encoding**  
   Каждая категория заменяется на среднее значение целевой переменной для этой категории.  
   Пример: средний доход по странам.

---

### Отбор признаков и работа с целевой переменной

1. Загрузили датасет и получили краткую информацию о данных.  
2. Построили базовую модель. Обнаружилось переобучение и высокая вариативность из-за большого числа признаков.  
3. Определили важность признаков.  
4. Отобрали топ-20 наиболее важных признаков и обучили линейную регрессию заново. Модель показала значительное улучшение качества, метрика R² стала положительной, что свидетельствует о росте точности.  
5. Автоматизировали отбор признаков с помощью метода `SelectFromModel` на основе случайного леса, уменьшив размерность с 202 до 53 признаков. После этого качество модели улучшилось ещё больше.  

---

### Работа с дисбалансом классов

- Рассмотрели задачу классификации на другом датасете (balance-scale).  
- Обучили логистическую регрессию, которая плохо распознавала миноритарный класс.  
- Применили взвешивание классов и oversampling (дублирование объектов миноритарного класса).  
- Значительно повысили точность и качество распознавания редкого класса.  

---

### Дискретизация целевой переменной (биннинг)

- Для задачи регрессии с сильно неравномерным распределением целевой переменной применили биннинг с помощью `KBinsDiscretizer`.  
- Рассмотрели разные стратегии биннинга: равномерный и квантильный для получения более сбалансированных категорий.

---

*Лабораторная работа 5. Сбор и подготовка данных, инжиниринг и отбор признаков.*
