# Лабораторная работа №4  
## Метрики эффективности и диагностика моделей машинного обучения

---

### Метрики эффективности

Метрики используются для оценки качества построенной модели.

#### Метрики регрессии
- **R² (коэффициент детерминации)** — показывает, какую долю дисперсии целевой переменной объясняет модель.
- **MAE (Mean Absolute Error)** — средняя абсолютная ошибка, среднее значение абсолютных отклонений предсказанных значений от реальных.
- **MSE (Mean Squared Error)** — среднеквадратичная ошибка, среднее значение квадратов ошибок; иногда используют RMSE (корень из MSE).

#### Метрики классификации
- **Accuracy** — доля правильных ответов.
- **Precision (Прецизионность)** — доля верно предсказанных положительных объектов из всех объектов, предсказанных как положительные.
- **Recall (Полнота)** — доля верно предсказанных положительных объектов из всех фактически положительных.
- **F1-score** — гармоническое среднее Precision и Recall, применяется при несбалансированных классах.
- **ROC-AUC** — площадь под ROC-кривой, характеризует способность модели различать классы.

---

### Диагностические кривые

1. **ROC-кривая (Receiver Operating Characteristic curve)**  
   Отображает зависимость True Positive Rate (TPR) от False Positive Rate (FPR) при различных порогах классификации. ROC-AUC — численная оценка качества модели.

2. **PR-кривая (Precision-Recall curve)**  
   Отображает зависимость точности (Precision) от полноты (Recall). Особенно полезна при дисбалансе классов.

3. **Кривая обучения (Learning Curve)**  
   Показывает изменение точности (или ошибки) модели на обучающей и тестовой выборках при увеличении размера обучающего набора. Используется для диагностики переобучения и недообучения.

---

### Кросс-валидация

Метод оценки качества модели, при котором исходные данные разбиваются на несколько частей, и обучение происходит многократно на различных разбиениях.

- **k-fold** — стандартный вариант с k равными частями.
- **Stratified k-fold** — сохраняет пропорции классов в каждой части (важно при дисбалансе).
- **LOO (Leave-One-Out)** — крайний случай, когда количество частей равно количеству объектов.

---

### Недообучение (Underfitting)

- **Описание:** Модель слишком простая и не улавливает зависимость данных.
- **Признаки:** Низкая точность на обучающей и тестовой выборках.
- **Причины:** Недостаточное количество признаков, слишком простая модель.

---

### Переобучение (Overfitting)

- **Описание:** Модель слишком сложная и запоминает обучающие данные, теряя способность обобщать.
- **Признаки:** Высокая точность на обучающей выборке, низкая — на тестовой; большая разница между ними.
- **Причины:** Сложная модель, мало данных, подстройка под шум.

---

### Выявление переобучения и недообучения

Используется анализ кривых обучения — сравнение метрик качества на обучающей и тестовой выборках при разном размере обучающей выборки.

---

*Лабораторная работа 4. Оценка качества моделей и диагностика.*

